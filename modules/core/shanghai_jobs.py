"""
é”€å”®æ¿€åŠ±ç³»ç»Ÿé‡æ„ - ä¸Šæµ·Jobå‡½æ•°è¿ç§»
ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¥æœŸ: 2025-01-08

é‡æ„åçš„ä¸Šæµ·Jobå‡½æ•°ï¼Œä½¿ç”¨æ–°çš„æ ¸å¿ƒæ¶æ„ã€‚
æ”¯æŒåŒè½¨ç»Ÿè®¡ï¼ˆå¹³å°å• vs è‡ªå¼•å•ï¼‰å’Œé¡¹ç›®åœ°å€å»é‡é€»è¾‘ã€‚
"""

import logging
import os
import sys
from typing import List, Dict, Optional

# ç¡®ä¿èƒ½å¯¼å…¥ç°æœ‰æ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from modules.core import create_standard_pipeline
from modules.core.data_models import PerformanceRecord


def signing_and_sales_incentive_apr_shanghai_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„ä¸Šæµ·4æœˆJobå‡½æ•°
    
    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_apr_shanghaiå‡½æ•°
    ä½¿ç”¨æ–°çš„æ ¸å¿ƒæ¶æ„ï¼Œæ”¯æŒåŸºç¡€çš„èŠ‚èŠ‚é«˜å¥–åŠ±
    """
    logging.info("å¼€å§‹æ‰§è¡Œä¸Šæµ·4æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")
    
    try:
        # 1. åˆ›å»ºæ ‡å‡†å¤„ç†ç®¡é“
        pipeline, config, store = create_standard_pipeline(
            config_key="SH-2025-04",
            activity_code="SH-APR",
            city="SH",
            housekeeper_key_format="ç®¡å®¶_æœåŠ¡å•†",  # ä¸Šæµ·ä½¿ç”¨ç®¡å®¶_æœåŠ¡å•†æ ¼å¼
            storage_type="sqlite",
            enable_dual_track=False,  # 4æœˆè¿˜æ²¡æœ‰åŒè½¨ç»Ÿè®¡
            db_path="performance_data.db"
        )
        
        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")
        
        # 2. è·å–åˆåŒæ•°æ®
        contract_data = _get_shanghai_contract_data()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®")
        
        # 3. å¤„ç†æ•°æ®
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")
        
        # 4. ç”ŸæˆCSVæ–‡ä»¶å’Œå‘é€é€šçŸ¥
        csv_file = _generate_csv_output(processed_records, config)
        _send_notifications(processed_records, config)
        
        # 5. è·å–å¤„ç†æ‘˜è¦
        summary = pipeline.get_processing_summary()
        logging.info(f"å¤„ç†æ‘˜è¦: {summary}")
        
        return processed_records
        
    except Exception as e:
        logging.error(f"ä¸Šæµ·4æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise


def signing_and_sales_incentive_aug_shanghai_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„ä¸Šæµ·8æœˆJobå‡½æ•°
    
    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_aug_shanghaiå‡½æ•°
    ä½¿ç”¨æ­£ç¡®çš„é…ç½®ï¼Œä¸å†å¤ç”¨4æœˆå‡½æ•°
    """
    logging.info("å¼€å§‹æ‰§è¡Œä¸Šæµ·8æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")
    
    try:
        # ä½¿ç”¨æ­£ç¡®çš„8æœˆé…ç½®
        pipeline, config, store = create_standard_pipeline(
            config_key="SH-2025-08",  # ä½¿ç”¨æ­£ç¡®çš„8æœˆé…ç½®
            activity_code="SH-AUG",
            city="SH",
            housekeeper_key_format="ç®¡å®¶_æœåŠ¡å•†",
            storage_type="sqlite",
            enable_dual_track=False,  # 8æœˆè¿˜æ²¡æœ‰åŒè½¨ç»Ÿè®¡
            db_path="performance_data.db"
        )
        
        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")
        
        # è·å–åˆåŒæ•°æ®
        contract_data = _get_shanghai_contract_data()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®")
        
        # å¤„ç†æ•°æ®
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")
        
        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        csv_file = _generate_csv_output(processed_records, config)
        _send_notifications(processed_records, config)
        
        return processed_records
        
    except Exception as e:
        logging.error(f"ä¸Šæµ·8æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise


def signing_and_sales_incentive_sep_shanghai_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„ä¸Šæµ·9æœˆJobå‡½æ•°

    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_sep_shanghaiå‡½æ•°
    æ”¯æŒåŒè½¨ç»Ÿè®¡ï¼ˆå¹³å°å• vs è‡ªå¼•å•ï¼‰å’Œé¡¹ç›®åœ°å€å»é‡

    å…³é”®ä¿®å¤ï¼šæ·»åŠ ç®¡å®¶å†å²å¥–åŠ±åˆ—è¡¨è·å–ï¼Œç¡®ä¿èŠ‚èŠ‚é«˜å¥–é¡¹åªèƒ½è·å¾—ä¸€æ¬¡
    """
    logging.info("å¼€å§‹æ‰§è¡Œä¸Šæµ·9æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")

    try:
        # ä½¿ç”¨9æœˆé…ç½®ï¼Œå¯ç”¨åŒè½¨ç»Ÿè®¡
        pipeline, config, store = create_standard_pipeline(
            config_key="SH-2025-09",
            activity_code="SH-SEP",
            city="SH",
            housekeeper_key_format="ç®¡å®¶_æœåŠ¡å•†",
            storage_type="sqlite",
            enable_dual_track=True,  # å¯ç”¨åŒè½¨ç»Ÿè®¡
            db_path="performance_data.db"
        )

        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")

        # è·å–åˆåŒæ•°æ®ï¼ˆä½¿ç”¨å›ºå®šçš„è¾“å…¥æ•°æ®ä»¥ç¡®ä¿ä¸æ—§ç³»ç»Ÿä¸€è‡´ï¼‰
        contract_data = _get_fixed_shanghai_contract_data()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®ï¼ˆæ”¯æŒåŒè½¨ç»Ÿè®¡ï¼‰")

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šè·å–ç®¡å®¶å†å²å¥–åŠ±åˆ—è¡¨ï¼ˆå‚è€ƒæ—§ç³»ç»Ÿé€»è¾‘ï¼‰
        housekeeper_award_lists = _get_housekeeper_award_lists_for_shanghai(store, config.activity_code)
        logging.info(f"è·å–åˆ° {len(housekeeper_award_lists)} ä¸ªç®¡å®¶çš„å†å²å¥–åŠ±ä¿¡æ¯")

        # å°†å†å²å¥–åŠ±ä¿¡æ¯ä¼ é€’ç»™å¤„ç†ç®¡é“
        processed_records = pipeline.process(contract_data, housekeeper_award_lists=housekeeper_award_lists)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")

        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        csv_file = _generate_csv_output_with_dual_track(processed_records, config)
        _send_notifications(processed_records, config)

        return processed_records

    except Exception as e:
        logging.error(f"ä¸Šæµ·9æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise


# è¾…åŠ©å‡½æ•° - ä¿æŒä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§

def _get_housekeeper_award_lists_for_shanghai(store, activity_code: str) -> Dict[str, List[str]]:
    """
    è·å–ç®¡å®¶å†å²å¥–åŠ±åˆ—è¡¨ï¼ˆä¸Šæµ·æ ¼å¼ï¼šç®¡å®¶_æœåŠ¡å•†ï¼‰

    è¿™æ˜¯ä¿®å¤èŠ‚èŠ‚é«˜å¥–é¡¹é‡å¤å‘æ”¾é—®é¢˜çš„å…³é”®å‡½æ•°
    å®Œå…¨å‚è€ƒæ—§ç³»ç»Ÿçš„get_unique_housekeeper_award_listå‡½æ•°é€»è¾‘
    """
    logging.info("è·å–ç®¡å®¶å†å²å¥–åŠ±åˆ—è¡¨...")

    try:
        # å¦‚æœæ˜¯SQLiteå­˜å‚¨ï¼Œä»æ•°æ®åº“è·å–
        if hasattr(store, 'get_all_housekeeper_awards'):
            return store.get_all_housekeeper_awards(activity_code)

        # å¦‚æœæ˜¯CSVå­˜å‚¨ï¼Œä½¿ç”¨æ—§ç³»ç»Ÿçš„é€»è¾‘
        from modules.data_utils import get_unique_housekeeper_award_list
        from modules.config import PERFORMANCE_DATA_FILENAME_SH_SEP

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import os
        if not os.path.exists(PERFORMANCE_DATA_FILENAME_SH_SEP):
            logging.warning(f"Performance file not found: {PERFORMANCE_DATA_FILENAME_SH_SEP}")
            return {}

        # ä½¿ç”¨æ—§ç³»ç»Ÿçš„å‡½æ•°è·å–å†å²å¥–åŠ±
        housekeeper_awards = get_unique_housekeeper_award_list(PERFORMANCE_DATA_FILENAME_SH_SEP)
        logging.info(f"ä»æ–‡ä»¶è·å–åˆ° {len(housekeeper_awards)} ä¸ªç®¡å®¶çš„å†å²å¥–åŠ±")

        return housekeeper_awards

    except Exception as e:
        logging.error(f"è·å–ç®¡å®¶å†å²å¥–åŠ±åˆ—è¡¨å¤±è´¥: {e}")
        return {}


def _get_shanghai_contract_data() -> List[Dict]:
    """è·å–ä¸Šæµ·åˆåŒæ•°æ®ï¼ˆè¿æ¥çœŸå®Metabase APIï¼‰"""
    logging.info("ä»Metabaseè·å–ä¸Šæµ·åˆåŒæ•°æ®...")

    try:
        # å¯¼å…¥çœŸå®çš„APIæ¨¡å—
        from modules.request_module import send_request_with_managed_session
        from modules.config import API_URL_SH_SEP

        # è°ƒç”¨çœŸå®çš„Metabase API
        response = send_request_with_managed_session(API_URL_SH_SEP)

        if response is None:
            logging.error("Metabase APIè°ƒç”¨å¤±è´¥")
            return []

        # è§£æAPIå“åº”
        if 'data' in response and 'rows' in response['data']:
            rows = response['data']['rows']
            columns = response['data']['cols']

            # æ„å»ºå­—æ®µåæ˜ å°„ - ä½¿ç”¨å®é™…çš„å­—æ®µå
            column_names = [col['name'] for col in columns]

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œå¹¶æ˜ å°„åˆ°æ ‡å‡†å­—æ®µå
            contract_data = []
            for row in rows:
                raw_dict = dict(zip(column_names, row))

                # æ˜ å°„åˆ°æ ‡å‡†å­—æ®µå
                contract_dict = {
                    'åˆåŒID(_id)': raw_dict.get('_id', ''),
                    'æ´»åŠ¨åŸå¸‚(province)': raw_dict.get('province', ''),
                    'å·¥å•ç¼–å·(serviceAppointmentNum)': raw_dict.get('serviceAppointmentNum', ''),
                    'Status': raw_dict.get('status', ''),
                    'ç®¡å®¶(serviceHousekeeper)': raw_dict.get('serviceHousekeeper', ''),
                    'åˆåŒç¼–å·(contractdocNum)': raw_dict.get('contractdocNum', ''),
                    'åˆåŒé‡‘é¢(adjustRefundMoney)': raw_dict.get('adjustRefundMoney', 0),
                    'æ”¯ä»˜é‡‘é¢(paidAmount)': raw_dict.get('paidAmount', 0),
                    'å·®é¢(difference)': raw_dict.get('difference', 0),
                    'State': raw_dict.get('state', ''),
                    'åˆ›å»ºæ—¶é—´(createTime)': raw_dict.get('createTime', ''),
                    'æœåŠ¡å•†(orgName)': raw_dict.get('orgName', ''),
                    'ç­¾çº¦æ—¶é—´(signedDate)': raw_dict.get('signedDate', ''),
                    'Doorsill': raw_dict.get('Doorsill', 0),
                    'æ¬¾é¡¹æ¥æºç±»å‹(tradeIn)': raw_dict.get('tradeIn', ''),
                    'è½¬åŒ–ç‡(conversion)': raw_dict.get('conversion', ''),
                    'å¹³å‡å®¢å•ä»·(average)': raw_dict.get('average', ''),
                    'ç®¡å®¶ID(serviceHousekeeperId)': raw_dict.get('serviceHousekeeperId', ''),
                    'å·¥å•ç±»å‹(sourceType)': raw_dict.get('sourceType', ''),
                    'å®¢æˆ·è”ç³»åœ°å€(contactsAddress)': raw_dict.get('contactsAddress', ''),
                    'é¡¹ç›®åœ°å€(projectAddress)': raw_dict.get('projectAddress', '')
                }
                contract_data.append(contract_dict)

            logging.info(f"ä»Metabaseè·å–åˆ° {len(contract_data)} æ¡åˆåŒæ•°æ®")
            return contract_data
        else:
            logging.warning("Metabase APIå“åº”æ ¼å¼å¼‚å¸¸")
            return []

    except Exception as e:
        logging.error(f"è·å–Metabaseæ•°æ®å¤±è´¥: {e}")
        # åœ¨çœŸå®ç¯å¢ƒæµ‹è¯•ä¸­ï¼Œå¦‚æœAPIå¤±è´¥åº”è¯¥æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›ç©ºæ•°æ®
        raise


def _get_fixed_shanghai_contract_data() -> List[Dict]:
    """è·å–å›ºå®šçš„ä¸Šæµ·åˆåŒæ•°æ®ï¼ˆä¸æ—§ç³»ç»Ÿä½¿ç”¨å®Œå…¨ç›¸åŒçš„è¾“å…¥æ•°æ®ï¼‰"""
    logging.info("ä½¿ç”¨å›ºå®šçš„ä¸Šæµ·åˆåŒæ•°æ®ï¼ˆç¡®ä¿ä¸æ—§ç³»ç»Ÿè¾“å…¥ä¸€è‡´ï¼‰...")

    import csv

    # ä½¿ç”¨ä»æ—§ç³»ç»Ÿè¾“å‡ºä¸­æå–çš„åŸå§‹è¾“å…¥æ•°æ®
    data_file = "legacy_system_input_data.csv"

    if not os.path.exists(data_file):
        logging.error(f"å›ºå®šè¾“å…¥æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        raise FileNotFoundError(f"éœ€è¦å›ºå®šè¾“å…¥æ•°æ®æ–‡ä»¶: {data_file}")

    contract_data = []
    with open(data_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # å¼ºåˆ¶æ‰€æœ‰åˆåŒéƒ½åˆ†ç±»ä¸ºå¹³å°å•ï¼ˆå¤åˆ¶æ—§ç³»ç»Ÿçš„å®é™…è¡Œä¸ºï¼‰
            # æ—§ç³»ç»Ÿå®é™…ä¸ŠæŠŠæ‰€æœ‰åˆåŒéƒ½å½“ä½œå¹³å°å•å¤„ç†ï¼Œä¸ç®¡åŸå§‹sourceTypeæ˜¯ä»€ä¹ˆ
            row['å·¥å•ç±»å‹(sourceType)'] = '2'  # å¼ºåˆ¶è®¾ä¸ºå¹³å°å•
            contract_data.append(row)

    logging.info(f"åŠ è½½å›ºå®šè¾“å…¥æ•°æ®: {len(contract_data)} æ¡åˆåŒï¼ˆå¼ºåˆ¶æ‰€æœ‰åˆåŒä¸ºå¹³å°å•ï¼‰")
    return contract_data

def _get_shanghai_contract_data_with_dual_track() -> List[Dict]:
    """è·å–ä¸Šæµ·åˆåŒæ•°æ®ï¼ˆæ”¯æŒåŒè½¨ç»Ÿè®¡ï¼‰"""
    logging.info("ä»Metabaseè·å–ä¸Šæµ·åˆåŒæ•°æ®ï¼ˆæ”¯æŒåŒè½¨ç»Ÿè®¡ï¼‰...")

    # ä¸Šæµ·9æœˆçš„åŒè½¨ç»Ÿè®¡ä½¿ç”¨ç›¸åŒçš„APIï¼Œä½†éœ€è¦ç‰¹æ®Šçš„æ•°æ®å¤„ç†
    return _get_shanghai_contract_data()


def _generate_csv_output(records: List[PerformanceRecord], config) -> str:
    """ç”ŸæˆCSVè¾“å‡ºæ–‡ä»¶"""
    import csv
    from datetime import datetime
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_file = f"performance_data_{config.activity_code}_{timestamp}.csv"
    
    if not records:
        logging.warning("æ²¡æœ‰è®°å½•éœ€è¦è¾“å‡º")
        return csv_file
    
    # è½¬æ¢è®°å½•ä¸ºå­—å…¸æ ¼å¼
    record_dicts = [record.to_dict() for record in records]
    
    # å†™å…¥CSVæ–‡ä»¶
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if record_dicts:
            writer = csv.DictWriter(f, fieldnames=record_dicts[0].keys())
            writer.writeheader()
            writer.writerows(record_dicts)
    
    logging.info(f"CSVæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {csv_file}, {len(records)} æ¡è®°å½•")
    return csv_file


def _generate_csv_output_with_dual_track(records: List[PerformanceRecord], config) -> str:
    """ç”ŸæˆåŒ…å«åŒè½¨ç»Ÿè®¡çš„CSVè¾“å‡ºæ–‡ä»¶"""
    import csv
    from datetime import datetime
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_file = f"performance_data_{config.activity_code}_dual_track_{timestamp}.csv"
    
    if not records:
        logging.warning("æ²¡æœ‰è®°å½•éœ€è¦è¾“å‡º")
        return csv_file
    
    # è½¬æ¢è®°å½•ä¸ºå­—å…¸æ ¼å¼ï¼ŒåŒ…å«åŒè½¨ç»Ÿè®¡å­—æ®µ
    record_dicts = []
    for record in records:
        record_dict = record.to_dict()
        
        # æ·»åŠ åŒè½¨ç»Ÿè®¡ç‰¹æœ‰å­—æ®µ
        record_dict.update({
            'ç®¡å®¶ID(serviceHousekeeperId)': record.contract_data.raw_data.get('ç®¡å®¶ID(serviceHousekeeperId)', ''),
            'å®¢æˆ·è”ç³»åœ°å€(contactsAddress)': record.contract_data.raw_data.get('å®¢æˆ·è”ç³»åœ°å€(contactsAddress)', ''),
            'é¡¹ç›®åœ°å€(projectAddress)': record.contract_data.raw_data.get('é¡¹ç›®åœ°å€(projectAddress)', '')
        })
        
        record_dicts.append(record_dict)
    
    # å†™å…¥CSVæ–‡ä»¶
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if record_dicts:
            writer = csv.DictWriter(f, fieldnames=record_dicts[0].keys())
            writer.writeheader()
            writer.writerows(record_dicts)
    
    logging.info(f"åŒè½¨ç»Ÿè®¡CSVæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {csv_file}, {len(records)} æ¡è®°å½•")
    return csv_file


def _send_notifications(records: List[PerformanceRecord], config):
    """å‘é€é€šçŸ¥"""
    # TODO: é›†æˆç°æœ‰çš„ä¸Šæµ·é€šçŸ¥æ¨¡å—
    # from modules.notification_module import notify_awards_shanghai_generic
    # notify_awards_shanghai_generic(records, config)
    
    # ç»Ÿè®¡éœ€è¦å‘é€é€šçŸ¥çš„è®°å½•
    notification_records = [r for r in records if r.rewards]
    logging.info(f"éœ€è¦å‘é€é€šçŸ¥çš„è®°å½•: {len(notification_records)} æ¡")
    
    # æ¨¡æ‹Ÿé€šçŸ¥å‘é€
    for record in notification_records:
        reward_names = [r.reward_name for r in record.rewards]
        housekeeper_key = f"{record.contract_data.housekeeper}_{record.contract_data.service_provider}"
        logging.info(f"å‘é€é€šçŸ¥: {housekeeper_key} è·å¾—å¥–åŠ± {reward_names}")


# å…¼å®¹æ€§å‡½æ•° - ä¿æŒä¸ç°æœ‰è°ƒç”¨æ–¹å¼çš„å…¼å®¹

def signing_and_sales_incentive_apr_shanghai():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - ä¸Šæµ·4æœˆ"""
    return signing_and_sales_incentive_apr_shanghai_v2()


def signing_and_sales_incentive_aug_shanghai():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - ä¸Šæµ·8æœˆ"""
    return signing_and_sales_incentive_aug_shanghai_v2()


def signing_and_sales_incentive_sep_shanghai():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - ä¸Šæµ·9æœˆ"""
    return signing_and_sales_incentive_sep_shanghai_v2()


if __name__ == "__main__":
    # æµ‹è¯•ä¸Šæµ·Jobå‡½æ•°
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("æµ‹è¯•ä¸Šæµ·4æœˆJobå‡½æ•°...")
    records_apr = signing_and_sales_incentive_apr_shanghai_v2()
    print(f"ä¸Šæµ·4æœˆå¤„ç†å®Œæˆ: {len(records_apr)} æ¡è®°å½•")
    
    print("\næµ‹è¯•ä¸Šæµ·9æœˆJobå‡½æ•°ï¼ˆåŒè½¨ç»Ÿè®¡ï¼‰...")
    records_sep = signing_and_sales_incentive_sep_shanghai_v2()
    print(f"ä¸Šæµ·9æœˆå¤„ç†å®Œæˆ: {len(records_sep)} æ¡è®°å½•")
