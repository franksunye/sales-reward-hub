"""
é”€å”®æ¿€åŠ±ç³»ç»Ÿé‡æ„ - åŒ—äº¬Jobå‡½æ•°è¿ç§»
ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¥æœŸ: 2025-01-08

é‡æ„åçš„åŒ—äº¬Jobå‡½æ•°ï¼Œä½¿ç”¨æ–°çš„æ ¸å¿ƒæ¶æ„ã€‚
æ›¿ä»£ç°æœ‰çš„é‡å¤Jobå‡½æ•°ï¼Œæ¶ˆé™¤å…¨å±€å‰¯ä½œç”¨ã€‚
"""

import logging
import os
import sys
from typing import List, Dict, Optional

# ç¡®ä¿èƒ½å¯¼å…¥ç°æœ‰æ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from modules.core import create_standard_pipeline
from modules.core.data_models import PerformanceRecord


def signing_and_sales_incentive_jun_beijing_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„åŒ—äº¬6æœˆJobå‡½æ•°
    
    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_jun_beijingå‡½æ•°
    ä½¿ç”¨æ–°çš„æ ¸å¿ƒæ¶æ„ï¼Œæ¶ˆé™¤é‡å¤ä»£ç å’Œå…¨å±€å‰¯ä½œç”¨
    """
    logging.info("å¼€å§‹æ‰§è¡ŒåŒ—äº¬6æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")
    
    try:
        # 1. åˆ›å»ºæ ‡å‡†å¤„ç†ç®¡é“
        pipeline, config, store = create_standard_pipeline(
            config_key="BJ-2025-06",
            activity_code="BJ-JUN",
            city="BJ",
            housekeeper_key_format="ç®¡å®¶",
            storage_type="sqlite",
            enable_project_limit=True,  # åŒ—äº¬å¯ç”¨å·¥å•é‡‘é¢ä¸Šé™
            db_path="performance_data.db"
        )
        
        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")
        
        # 2. è·å–åˆåŒæ•°æ®ï¼ˆä¿æŒç°æœ‰APIè°ƒç”¨æ–¹å¼ï¼‰
        contract_data = _get_contract_data_from_metabase()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®")
        
        # 3. å¤„ç†æ•°æ®
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")
        
        # 4. ç”ŸæˆCSVæ–‡ä»¶ï¼ˆå¯é…ç½®ï¼‰
        if config.enable_csv_output:
            csv_file = _generate_csv_output(processed_records, config)
            logging.info(f"ç”ŸæˆCSVæ–‡ä»¶: {csv_file}")
        else:
            logging.info("CSVè¾“å‡ºå·²ç¦ç”¨ï¼Œæ•°æ®ä»…ä¿å­˜åˆ°æ•°æ®åº“")
        
        # 5. å‘é€é€šçŸ¥ï¼ˆä¿æŒç°æœ‰é€šçŸ¥é€»è¾‘ï¼‰
        _send_notifications(processed_records, config)
        logging.info("é€šçŸ¥å‘é€å®Œæˆ")
        
        # 6. è·å–å¤„ç†æ‘˜è¦
        summary = pipeline.get_processing_summary()
        logging.info(f"å¤„ç†æ‘˜è¦: {summary}")
        
        return processed_records
        
    except Exception as e:
        logging.error(f"åŒ—äº¬6æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise


def signing_and_sales_incentive_aug_beijing_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„åŒ—äº¬8æœˆJobå‡½æ•°
    
    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_aug_beijingå‡½æ•°
    ä½¿ç”¨æ­£ç¡®çš„é…ç½®ï¼Œä¸å†å¤ç”¨6æœˆå‡½æ•°
    """
    logging.info("å¼€å§‹æ‰§è¡ŒåŒ—äº¬8æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")
    
    try:
        # ä½¿ç”¨æ­£ç¡®çš„8æœˆé…ç½®
        pipeline, config, store = create_standard_pipeline(
            config_key="BJ-2025-08",  # ä½¿ç”¨æ­£ç¡®çš„8æœˆé…ç½®
            activity_code="BJ-AUG",
            city="BJ",
            housekeeper_key_format="ç®¡å®¶",
            storage_type="sqlite",
            enable_project_limit=True,
            db_path="performance_data.db"
        )
        
        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")
        
        # è·å–åˆåŒæ•°æ®
        contract_data = _get_contract_data_from_metabase()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®")
        
        # å¤„ç†æ•°æ®
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")
        
        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        if config.enable_csv_output:
            csv_file = _generate_csv_output(processed_records, config)
            logging.info(f"ç”ŸæˆCSVæ–‡ä»¶: {csv_file}")
        _send_notifications(processed_records, config)
        
        return processed_records
        
    except Exception as e:
        logging.error(f"åŒ—äº¬8æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise


def signing_and_sales_incentive_sep_beijing_v2() -> List[PerformanceRecord]:
    """
    é‡æ„åçš„åŒ—äº¬9æœˆJobå‡½æ•°
    
    æ›¿ä»£åŸæœ‰çš„signing_and_sales_incentive_sep_beijingå‡½æ•°
    æ¶ˆé™¤å…¨å±€å‰¯ä½œç”¨ï¼Œæ”¯æŒå†å²åˆåŒå¤„ç†
    """
    logging.info("å¼€å§‹æ‰§è¡ŒåŒ—äº¬9æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")
    
    try:
        # ä½¿ç”¨æ­£ç¡®çš„9æœˆé…ç½®ï¼Œæ”¯æŒå†å²åˆåŒ
        pipeline, config, store = create_standard_pipeline(
            config_key="BJ-2025-09",  # ç›´æ¥ä½¿ç”¨æ­£ç¡®é…ç½®
            activity_code="BJ-SEP",
            city="BJ",
            housekeeper_key_format="ç®¡å®¶",
            storage_type="sqlite",
            enable_project_limit=True,
            enable_historical_contracts=True,  # æ”¯æŒå†å²åˆåŒå¤„ç†
            db_path="performance_data.db"
        )
        
        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")
        
        # è·å–åˆåŒæ•°æ®ï¼ˆåŒ…å«å†å²åˆåŒï¼‰
        contract_data = _get_contract_data_with_historical()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®ï¼ˆåŒ…å«å†å²åˆåŒï¼‰")
        
        # å¤„ç†æ•°æ® - æ— éœ€å…¨å±€å‰¯ä½œç”¨
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")
        
        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        if config.enable_csv_output:
            csv_file = _generate_csv_output(processed_records, config)
            logging.info(f"ç”ŸæˆCSVæ–‡ä»¶: {csv_file}")
        _send_notifications(processed_records, config)
        
        return processed_records
        
    except Exception as e:
        logging.error(f"åŒ—äº¬9æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise


# è¾…åŠ©å‡½æ•° - ä¿æŒä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§

def _parse_metabase_response(response: dict) -> List[Dict]:
    """
    é€šç”¨çš„Metabase APIå“åº”è§£æå‡½æ•°

    å°†Metabase APIè¿”å›çš„åŸå§‹æ•°æ®ï¼ˆè‹±æ–‡å­—æ®µåï¼‰è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼ˆä¸­æ–‡å­—æ®µåï¼‰

    Args:
        response: Metabase APIè¿”å›çš„å“åº”å­—å…¸

    Returns:
        è½¬æ¢åçš„åˆåŒæ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«ä¸­æ–‡å­—æ®µåçš„å­—å…¸
    """
    if not response or not isinstance(response, dict) or 'data' not in response:
        logging.warning("APIå“åº”ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
        return []

    data = response['data']
    if not data or 'rows' not in data or 'cols' not in data:
        logging.warning("APIæ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼šç¼ºå°‘rowsæˆ–colså­—æ®µ")
        return []

    rows = data['rows']
    columns = data['cols']

    if not rows:
        logging.warning("æ²¡æœ‰è·å–åˆ°åˆåŒæ•°æ®")
        return []

    # æ„å»ºå­—æ®µåæ˜ å°„
    column_names = [col['name'] for col in columns]

    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œå¹¶æ˜ å°„åˆ°æ ‡å‡†å­—æ®µå
    contract_data = []
    for row in rows:
        raw_dict = dict(zip(column_names, row))

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šsourceType å­—æ®µå¤„ç†
        # API è¿”å›çš„ sourceType å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—ï¼Œéœ€è¦è½¬æ¢ä¸ºæ•°å­—
        # é»˜è®¤å€¼ä¸º 2ï¼ˆå¹³å°å•ï¼‰
        source_type = raw_dict.get('sourceType', 2)
        if isinstance(source_type, str):
            try:
                source_type = int(source_type)
            except (ValueError, TypeError):
                source_type = 2  # è½¬æ¢å¤±è´¥æ—¶é»˜è®¤ä¸ºå¹³å°å•

        # æ˜ å°„åˆ°æ ‡å‡†å­—æ®µåï¼ˆä¸­æ–‡ï¼‰
        contract_dict = {
            'åˆåŒID(_id)': raw_dict.get('_id', ''),
            'æ´»åŠ¨åŸå¸‚(province)': raw_dict.get('province', ''),
            'å·¥å•ç¼–å·(serviceAppointmentNum)': raw_dict.get('serviceAppointmentNum', ''),
            'Status': raw_dict.get('status', ''),
            'ç®¡å®¶(serviceHousekeeper)': raw_dict.get('serviceHousekeeper', ''),
            'åˆåŒç¼–å·(contractdocNum)': raw_dict.get('contractdocNum', ''),
            'åˆåŒé‡‘é¢(adjustRefundMoney)': raw_dict.get('adjustRefundMoney', 0),
            'æ”¯ä»˜é‡‘é¢(paidAmount)': raw_dict.get('paidAmount', 0),
            'å·®é¢(difference)': raw_dict.get('difference', 0),
            'State': raw_dict.get('state', ''),
            'åˆ›å»ºæ—¶é—´(createTime)': raw_dict.get('createTime', ''),
            'æœåŠ¡å•†(orgName)': raw_dict.get('orgName', ''),
            'ç­¾çº¦æ—¶é—´(signedDate)': raw_dict.get('signedDate', ''),
            'Doorsill': raw_dict.get('Doorsill', 0),
            'æ¬¾é¡¹æ¥æºç±»å‹(tradeIn)': raw_dict.get('tradeIn', ''),
            'è½¬åŒ–ç‡(conversion)': raw_dict.get('conversion', 0),
            'å¹³å‡å®¢å•ä»·(average)': raw_dict.get('average', 0),
            'ç®¡å®¶ID(serviceHousekeeperId)': raw_dict.get('serviceHousekeeperId', ''),
            'å·¥å•ç±»å‹(sourceType)': source_type,  # âœ… ä½¿ç”¨è½¬æ¢åçš„æ•°å­—å€¼
            'è”ç³»åœ°å€(contactsAddress)': raw_dict.get('contactsAddress', ''),
            'é¡¹ç›®åœ°å€(projectAddress)': raw_dict.get('projectAddress', ''),
        }
        contract_data.append(contract_dict)

    return contract_data


def _get_contract_data_from_metabase() -> List[Dict]:
    """è·å–åˆåŒæ•°æ®ï¼ˆè¿æ¥çœŸå®Metabase APIï¼‰- åŒ—äº¬9æœˆ"""
    logging.info("ä»Metabaseè·å–åŒ—äº¬9æœˆåˆåŒæ•°æ®...")

    try:
        # å¯¼å…¥çœŸå®çš„APIæ¨¡å—
        from modules.request_module import send_request_with_managed_session
        from modules.config import API_URL_BJ_SEP

        # è°ƒç”¨çœŸå®çš„Metabase API
        response = send_request_with_managed_session(API_URL_BJ_SEP)

        if response is None:
            logging.error("Metabase APIè°ƒç”¨å¤±è´¥")
            return []

        # ä½¿ç”¨é€šç”¨çš„è§£æå‡½æ•°
        contract_data = _parse_metabase_response(response)
        if contract_data:
            logging.info(f"ä»Metabaseè·å–åˆ° {len(contract_data)} æ¡åˆåŒæ•°æ®")
        return contract_data

    except Exception as e:
        logging.error(f"è·å–Metabaseæ•°æ®å¤±è´¥: {e}")
        # åœ¨çœŸå®ç¯å¢ƒæµ‹è¯•ä¸­ï¼Œå¦‚æœAPIå¤±è´¥åº”è¯¥æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›ç©ºæ•°æ®
        raise


def _get_contract_data_with_source_type() -> List[Dict]:
    """è·å–åŒ…å«sourceTypeå­—æ®µçš„åˆåŒæ•°æ®ï¼ˆåŒ—äº¬10æœˆä¸“ç”¨ï¼‰"""
    logging.info("ä»Metabaseè·å–åŒ—äº¬10æœˆåˆåŒæ•°æ®ï¼ˆåŒ…å«åŒè½¨ä¿¡æ¯ï¼‰...")

    try:
        # å¯¼å…¥çœŸå®çš„APIæ¨¡å—
        from modules.request_module import send_request_with_managed_session
        from modules.config import API_URL_BJ_OCT  # åŒ—äº¬10æœˆAPIç«¯ç‚¹

        # è°ƒç”¨çœŸå®çš„Metabase API
        response = send_request_with_managed_session(API_URL_BJ_OCT)

        if response is None:
            logging.error("Metabase APIè°ƒç”¨å¤±è´¥")
            return []

        # ä½¿ç”¨é€šç”¨çš„è§£æå‡½æ•°
        contract_data = _parse_metabase_response(response)
        if contract_data:
            logging.info(f"æˆåŠŸè·å– {len(contract_data)} ä¸ªåˆåŒæ•°æ®ï¼ŒåŒ…å«sourceTypeå­—æ®µ")
        return contract_data

    except Exception as e:
        logging.error(f"è·å–åŒ—äº¬10æœˆåˆåŒæ•°æ®å¤±è´¥: {e}")
        raise


def _get_contract_data_with_historical() -> List[Dict]:
    """è·å–åˆåŒæ•°æ®ï¼ˆåŒ…å«å†å²åˆåŒï¼‰"""
    logging.info("ä»Metabaseè·å–åˆåŒæ•°æ®ï¼ˆåŒ…å«å†å²åˆåŒï¼‰...")

    # è·å–åŸºç¡€æ•°æ®
    contract_data = _get_contract_data_from_metabase()
    
    # æ·»åŠ å†å²åˆåŒæ ‡è®°
    for contract in contract_data:
        # å¦‚æœå†å²åˆåŒç¼–å·å­—æ®µæœ‰å€¼ä¸”ä¸ä¸ºç©ºï¼Œåˆ™æ ‡è®°ä¸ºå†å²åˆåŒ
        pc_contract_doc_num = contract.get('pcContractdocNum', '')
        if pc_contract_doc_num and str(pc_contract_doc_num).strip():
            contract['is_historical'] = True
        else:
            contract['is_historical'] = False
    
    return contract_data


def _generate_csv_output(records: List[PerformanceRecord], config) -> str:
    """ç”ŸæˆCSVè¾“å‡ºæ–‡ä»¶"""
    import csv
    from datetime import datetime
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_file = f"performance_data_{config.activity_code}_{timestamp}.csv"
    
    if not records:
        logging.warning("æ²¡æœ‰è®°å½•éœ€è¦è¾“å‡º")
        return csv_file
    
    # è½¬æ¢è®°å½•ä¸ºå­—å…¸æ ¼å¼
    record_dicts = [record.to_dict() for record in records]

    # å†™å…¥CSVæ–‡ä»¶
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if record_dicts:
            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„å­—æ®µå
            all_fieldnames = set()
            for record_dict in record_dicts:
                all_fieldnames.update(record_dict.keys())

            writer = csv.DictWriter(f, fieldnames=sorted(all_fieldnames))
            writer.writeheader()
            writer.writerows(record_dicts)
    
    logging.info(f"CSVæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {csv_file}, {len(records)} æ¡è®°å½•")
    return csv_file


def _send_notifications(records: List[PerformanceRecord], config):
    """å‘é€é€šçŸ¥ - ä½¿ç”¨æ–°æ¶æ„çš„é€šçŸ¥æœåŠ¡"""
    from .notification_service import create_notification_service
    from .storage import create_data_store

    # åˆ›å»ºå­˜å‚¨å®ä¾‹
    storage = create_data_store(
        storage_type="sqlite",
        db_path="performance_data.db"
    )

    # åˆ›å»ºé€šçŸ¥æœåŠ¡
    notification_service = create_notification_service(storage, config)

    # å‘é€é€šçŸ¥
    stats = notification_service.send_notifications()

    logging.info(f"é€šçŸ¥å‘é€å®Œæˆ - æ€»è®¡: {stats['total']}, ç¾¤é€šçŸ¥: {stats['group_notifications']}, å¥–åŠ±é€šçŸ¥: {stats['award_notifications']}")


# å…¼å®¹æ€§å‡½æ•° - ä¿æŒä¸ç°æœ‰è°ƒç”¨æ–¹å¼çš„å…¼å®¹

def signing_and_sales_incentive_jun_beijing():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - åŒ—äº¬6æœˆ"""
    return signing_and_sales_incentive_jun_beijing_v2()


def signing_and_sales_incentive_aug_beijing():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - åŒ—äº¬8æœˆ"""
    return signing_and_sales_incentive_aug_beijing_v2()


def signing_and_sales_incentive_sep_beijing():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - åŒ—äº¬9æœˆ"""
    return signing_and_sales_incentive_sep_beijing_v2()


def signing_and_sales_incentive_oct_beijing_v2() -> List[PerformanceRecord]:
    """
    åŒ—äº¬2025å¹´10æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡

    ç‰¹æ€§ï¼š
    - æ··åˆå¥–åŠ±ç­–ç•¥ï¼šå¹¸è¿æ•°å­—åŸºäºå¹³å°å•ï¼ŒèŠ‚èŠ‚é«˜åŸºäºæ€»ä¸šç»©
    - åŒè½¨ç»Ÿè®¡ï¼šæ”¯æŒå¹³å°å•å’Œè‡ªå¼•å•åˆ†åˆ«ç»Ÿè®¡
    - ä¸“ç”¨æ¶ˆæ¯æ¨¡æ¿ï¼šç»“åˆåŒ—äº¬ç‰¹è‰²çš„æ¶ˆæ¯æ ¼å¼
    - æ— è‡ªå¼•å•ç‹¬ç«‹å¥–åŠ±ï¼šç®€åŒ–æ¿€åŠ±é€»è¾‘
    """
    logging.info("å¼€å§‹æ‰§è¡ŒåŒ—äº¬10æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆé‡æ„ç‰ˆï¼‰")

    try:
        # åˆ›å»ºåŒ—äº¬10æœˆä¸“ç”¨å¤„ç†ç®¡é“
        pipeline, config, store = create_standard_pipeline(
            config_key="BJ-2025-10",  # ä½¿ç”¨åŒ—äº¬10æœˆé…ç½®
            activity_code="BJ-OCT",
            city="BJ",
            housekeeper_key_format="ç®¡å®¶",
            storage_type="sqlite",
            enable_project_limit=True,  # å¯ç”¨å·¥å•é‡‘é¢ä¸Šé™
            enable_dual_track=True,  # å¯ç”¨åŒè½¨ç»Ÿè®¡
            enable_historical_contracts=False,  # ä¸æ¶‰åŠå†å²å·¥å•
            db_path="performance_data.db"
        )

        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")

        # è·å–åˆåŒæ•°æ®ï¼ˆåŒ…å«sourceTypeå­—æ®µï¼‰
        contract_data = _get_contract_data_with_source_type()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®ï¼ˆåŒ…å«åŒè½¨ä¿¡æ¯ï¼‰")

        # å¤„ç†æ•°æ®
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")

        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        if config.enable_csv_output:
            csv_file = _generate_csv_output(processed_records, config)
            logging.info(f"ç”ŸæˆCSVæ–‡ä»¶: {csv_file}")
        _send_notifications(processed_records, config)

        return processed_records

    except Exception as e:
        logging.error(f"åŒ—äº¬10æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise


def signing_and_sales_incentive_oct_beijing():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - åŒ—äº¬10æœˆ"""
    return signing_and_sales_incentive_oct_beijing_v2()


def signing_and_sales_incentive_nov_beijing_v2() -> List[PerformanceRecord]:
    """
    åŒ—äº¬2025å¹´11æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆæ–°æ¶æ„ï¼‰

    ç‰¹ç‚¹ï¼š
    - ä»…æ’­æŠ¥æ¨¡å¼ï¼šä¸è®¡ç®—ä»»ä½•å¥–åŠ±
    - ä»…å¤„ç†å¹³å°å•
    - ä¸å¤„ç†å†å²åˆåŒ
    - ç®€åŒ–æ¶ˆæ¯æ¨¡æ¿
    """
    logging.info("å¼€å§‹æ‰§è¡ŒåŒ—äº¬11æœˆé”€å”®æ¿€åŠ±ä»»åŠ¡ï¼ˆä»…æ’­æŠ¥æ¨¡å¼ï¼‰")

    try:
        # åˆ›å»ºå¤„ç†ç®¡é“
        pipeline, config, store = create_standard_pipeline(
            config_key="BJ-2025-11",
            activity_code="BJ-NOV",
            city="BJ",
            housekeeper_key_format="ç®¡å®¶",
            storage_type="sqlite",
            enable_dual_track=False,  # ä¸å¯ç”¨åŒè½¨ç»Ÿè®¡
            enable_project_limit=False,  # ä¸å¯ç”¨å·¥å•ä¸Šé™
            enable_historical_contracts=False,  # ä¸å¤„ç†å†å²åˆåŒ
            db_path="performance_data.db"
        )

        logging.info(f"åˆ›å»ºå¤„ç†ç®¡é“æˆåŠŸ: {config.activity_code}")

        # è·å–åˆåŒæ•°æ®
        contract_data = _get_contract_data_from_metabase_nov()
        logging.info(f"è·å–åˆ° {len(contract_data)} ä¸ªåˆåŒæ•°æ®")

        # å¤„ç†æ•°æ®ï¼ˆä¼šè‡ªåŠ¨è¿‡æ»¤å¹³å°å•ï¼‰
        processed_records = pipeline.process(contract_data)
        logging.info(f"å¤„ç†å®Œæˆ: {len(processed_records)} æ¡è®°å½•")

        # ç”Ÿæˆè¾“å‡ºå’Œå‘é€é€šçŸ¥
        if config.enable_csv_output:
            csv_file = _generate_csv_output(processed_records, config)
            logging.info(f"ç”ŸæˆCSVæ–‡ä»¶: {csv_file}")
        _send_notifications(processed_records, config)

        return processed_records

    except Exception as e:
        logging.error(f"åŒ—äº¬11æœˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise


def _get_contract_data_from_metabase_nov() -> List[Dict]:
    """è·å–åŒ—äº¬11æœˆåˆåŒæ•°æ®"""
    logging.info("ä»Metabaseè·å–åŒ—äº¬11æœˆåˆåŒæ•°æ®...")

    try:
        from modules.config import API_URL_BJ_NOV
        from modules.request_module import send_request_with_managed_session

        response = send_request_with_managed_session(API_URL_BJ_NOV)

        if response is None:
            logging.error("Metabase APIè°ƒç”¨å¤±è´¥")
            return []

        # ä½¿ç”¨é€šç”¨çš„è§£æå‡½æ•°
        contract_data = _parse_metabase_response(response)
        if contract_data:
            logging.info(f"ä»Metabaseè·å–åˆ° {len(contract_data)} æ¡åˆåŒæ•°æ®")
        return contract_data

    except Exception as e:
        logging.error(f"è·å–åŒ—äº¬11æœˆåˆåŒæ•°æ®å¤±è´¥: {e}")
        raise


def signing_and_sales_incentive_nov_beijing():
    """å…¼å®¹æ€§åŒ…è£…å‡½æ•° - åŒ—äº¬11æœˆ"""
    return signing_and_sales_incentive_nov_beijing_v2()


if __name__ == "__main__":
    # æµ‹è¯•åŒ—äº¬Jobå‡½æ•°
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    print("æµ‹è¯•åŒ—äº¬6æœˆJobå‡½æ•°...")
    records_jun = signing_and_sales_incentive_jun_beijing_v2()
    print(f"åŒ—äº¬6æœˆå¤„ç†å®Œæˆ: {len(records_jun)} æ¡è®°å½•")

    print("\næµ‹è¯•åŒ—äº¬9æœˆJobå‡½æ•°...")
    records_sep = signing_and_sales_incentive_sep_beijing_v2()
    print(f"åŒ—äº¬9æœˆå¤„ç†å®Œæˆ: {len(records_sep)} æ¡è®°å½•")

    print("\næµ‹è¯•åŒ—äº¬10æœˆJobå‡½æ•°...")
    records_oct = signing_and_sales_incentive_oct_beijing_v2()
    print(f"åŒ—äº¬10æœˆå¤„ç†å®Œæˆ: {len(records_oct)} æ¡è®°å½•")

    print("\næµ‹è¯•åŒ—äº¬11æœˆJobå‡½æ•°...")
    records_nov = signing_and_sales_incentive_nov_beijing_v2()
    print(f"åŒ—äº¬11æœˆå¤„ç†å®Œæˆ: {len(records_nov)} æ¡è®°å½•")
