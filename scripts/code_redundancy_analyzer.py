#!/usr/bin/env python3
"""
ä»£ç å†—ä½™åˆ†æå·¥å…·

åˆ†æé¡¹ç›®ä¸­çš„å†—ä½™ä»£ç ï¼ŒåŒ…æ‹¬ï¼š
1. é‡å¤çš„å‡½æ•°
2. å…¼å®¹æ€§åŒ…è£…å‡½æ•°
3. é‡å¤çš„éªŒè¯å·¥å…·
4. æ— ç”¨çš„é…ç½®æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
    python scripts/code_redundancy_analyzer.py
    python scripts/code_redundancy_analyzer.py --output reports/redundancy_analysis.md
"""

import sys
import os
import ast
import re
from typing import Dict, List, Set, Tuple
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

class CodeRedundancyAnalyzer:
    """ä»£ç å†—ä½™åˆ†æå™¨"""
    
    def __init__(self):
        self.project_root = Path(project_root)
        self.analysis_result = {
            'timestamp': datetime.now().isoformat(),
            'duplicate_functions': [],
            'wrapper_functions': [],
            'redundant_scripts': [],
            'redundant_configs': [],
            'recommendations': []
        }
    
    def analyze_all(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” å¼€å§‹ä»£ç å†—ä½™åˆ†æ...")
        
        self.analyze_duplicate_functions()
        self.analyze_wrapper_functions()
        self.analyze_redundant_scripts()
        self.analyze_redundant_configs()
        self.generate_recommendations()
        
        print("âœ… åˆ†æå®Œæˆ")
    
    def analyze_duplicate_functions(self):
        """åˆ†æé‡å¤å‡½æ•°"""
        print("ğŸ“‹ åˆ†æé‡å¤å‡½æ•°...")
        
        # æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.project_root.rglob("*.py"))
        function_signatures = {}
        
        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        func_name = node.name
                        # ç®€å•çš„å‡½æ•°ç­¾åï¼ˆåç§°+å‚æ•°æ•°é‡ï¼‰
                        signature = f"{func_name}({len(node.args.args)})"
                        
                        if signature not in function_signatures:
                            function_signatures[signature] = []
                        
                        function_signatures[signature].append({
                            'file': str(file_path.relative_to(self.project_root)),
                            'name': func_name,
                            'line': node.lineno
                        })
                        
            except Exception as e:
                print(f"âš ï¸  è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„å‡½æ•°
        for signature, locations in function_signatures.items():
            if len(locations) > 1:
                # è¿‡æ»¤æ‰æ˜æ˜¾çš„æµ‹è¯•å‡½æ•°å’Œç‰¹æ®Šå‡½æ•°
                if not any(loc['name'].startswith(('test_', '__', '_test')) for loc in locations):
                    self.analysis_result['duplicate_functions'].append({
                        'signature': signature,
                        'locations': locations,
                        'count': len(locations)
                    })
    
    def analyze_wrapper_functions(self):
        """åˆ†æå…¼å®¹æ€§åŒ…è£…å‡½æ•°"""
        print("ğŸ“‹ åˆ†æå…¼å®¹æ€§åŒ…è£…å‡½æ•°...")
        
        wrapper_patterns = [
            r'def\s+(\w+)\s*\([^)]*\):\s*"""å…¼å®¹æ€§åŒ…è£…å‡½æ•°',
            r'def\s+(\w+)\s*\([^)]*\):\s*return\s+\w+_v2\(',
            r'# å…¼å®¹æ€§å‡½æ•°',
            r'å…¼å®¹æ€§åŒ…è£…'
        ]
        
        # æ£€æŸ¥ç‰¹å®šæ–‡ä»¶
        wrapper_files = [
            'modules/core/beijing_jobs.py',
            'modules/core/shanghai_jobs.py'
        ]
        
        for file_path in wrapper_files:
            full_path = self.project_root / file_path
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æŸ¥æ‰¾å…¼å®¹æ€§å‡½æ•°
                    for pattern in wrapper_patterns:
                        matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
                        for match in matches:
                            line_num = content[:match.start()].count('\n') + 1
                            self.analysis_result['wrapper_functions'].append({
                                'file': file_path,
                                'line': line_num,
                                'pattern': pattern,
                                'match': match.group(0)
                            })
                            
                except Exception as e:
                    print(f"âš ï¸  åˆ†æåŒ…è£…å‡½æ•°å¤±è´¥ {file_path}: {e}")
    
    def analyze_redundant_scripts(self):
        """åˆ†æå†—ä½™è„šæœ¬"""
        print("ğŸ“‹ åˆ†æå†—ä½™è„šæœ¬...")
        
        scripts_dir = self.project_root / 'scripts'
        if not scripts_dir.exists():
            return
        
        # æŒ‰åŠŸèƒ½åˆ†ç»„è„šæœ¬
        script_groups = {
            'validation': [],
            'comparison': [],
            'testing': [],
            'cleanup': [],
            'analysis': []
        }
        
        for script_file in scripts_dir.glob("*.py"):
            script_name = script_file.name.lower()
            
            if any(keyword in script_name for keyword in ['valid', 'check', 'verify']):
                script_groups['validation'].append(script_file.name)
            elif any(keyword in script_name for keyword in ['compare', 'diff', 'vs']):
                script_groups['comparison'].append(script_file.name)
            elif any(keyword in script_name for keyword in ['test', 'run']):
                script_groups['testing'].append(script_file.name)
            elif any(keyword in script_name for keyword in ['clean', 'clear', 'remove']):
                script_groups['cleanup'].append(script_file.name)
            elif any(keyword in script_name for keyword in ['analy', 'report', 'generate']):
                script_groups['analysis'].append(script_file.name)
        
        # è¯†åˆ«å¯èƒ½å†—ä½™çš„è„šæœ¬ç»„
        for group_name, scripts in script_groups.items():
            if len(scripts) > 3:  # å¦‚æœæŸç±»è„šæœ¬è¶…è¿‡3ä¸ªï¼Œå¯èƒ½æœ‰å†—ä½™
                self.analysis_result['redundant_scripts'].append({
                    'group': group_name,
                    'scripts': scripts,
                    'count': len(scripts),
                    'recommendation': f'è€ƒè™‘åˆå¹¶{group_name}ç±»è„šæœ¬'
                })
    
    def analyze_redundant_configs(self):
        """åˆ†æå†—ä½™é…ç½®"""
        print("ğŸ“‹ åˆ†æå†—ä½™é…ç½®...")
        
        config_files = [
            'modules/config.py',
            'modules/core/config_adapter.py',
            'modules/core/production_config.py'
        ]
        
        config_analysis = []
        
        for config_file in config_files:
            full_path = self.project_root / config_file
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ç»Ÿè®¡é…ç½®é¡¹æ•°é‡
                    reward_configs = content.count('REWARD_CONFIGS')
                    api_urls = content.count('API_URL')
                    file_paths = content.count('_FILE')
                    
                    config_analysis.append({
                        'file': config_file,
                        'size': len(content),
                        'lines': content.count('\n'),
                        'reward_configs': reward_configs,
                        'api_urls': api_urls,
                        'file_paths': file_paths
                    })
                    
                except Exception as e:
                    print(f"âš ï¸  åˆ†æé…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
        
        self.analysis_result['redundant_configs'] = config_analysis
    
    def generate_recommendations(self):
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # é‡å¤å‡½æ•°å»ºè®®
        if self.analysis_result['duplicate_functions']:
            recommendations.append({
                'category': 'é‡å¤å‡½æ•°',
                'priority': 'high',
                'description': f"å‘ç° {len(self.analysis_result['duplicate_functions'])} ç»„é‡å¤å‡½æ•°",
                'action': 'åˆå¹¶æˆ–é‡æ„é‡å¤å‡½æ•°ï¼Œä¿ç•™æœ€ä¼˜å®ç°'
            })
        
        # åŒ…è£…å‡½æ•°å»ºè®®
        if self.analysis_result['wrapper_functions']:
            recommendations.append({
                'category': 'å…¼å®¹æ€§åŒ…è£…',
                'priority': 'medium',
                'description': f"å‘ç° {len(self.analysis_result['wrapper_functions'])} ä¸ªå…¼å®¹æ€§åŒ…è£…å‡½æ•°",
                'action': 'è¯„ä¼°æ˜¯å¦ä»éœ€è¦å…¼å®¹æ€§åŒ…è£…ï¼Œè€ƒè™‘ç›´æ¥è¿ç§»åˆ°æ–°æ¶æ„'
            })
        
        # å†—ä½™è„šæœ¬å»ºè®®
        if self.analysis_result['redundant_scripts']:
            recommendations.append({
                'category': 'å†—ä½™è„šæœ¬',
                'priority': 'medium',
                'description': f"å‘ç° {len(self.analysis_result['redundant_scripts'])} ç»„å¯èƒ½å†—ä½™çš„è„šæœ¬",
                'action': 'åˆå¹¶åŠŸèƒ½ç›¸ä¼¼çš„è„šæœ¬ï¼Œä¿ç•™æœ€å®Œæ•´çš„ç‰ˆæœ¬'
            })
        
        # é…ç½®æ–‡ä»¶å»ºè®®
        if len(self.analysis_result['redundant_configs']) > 2:
            recommendations.append({
                'category': 'é…ç½®æ–‡ä»¶',
                'priority': 'high',
                'description': f"å‘ç° {len(self.analysis_result['redundant_configs'])} ä¸ªé…ç½®æ–‡ä»¶",
                'action': 'ç»Ÿä¸€é…ç½®ç³»ç»Ÿï¼Œé€‰æ‹©ä¸€ä¸ªä½œä¸ºæƒå¨æº'
            })
        
        self.analysis_result['recommendations'] = recommendations
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            '__pycache__',
            '.git',
            'venv',
            'env',
            '.pytest_cache',
            'node_modules'
        ]
        
        return any(pattern in str(file_path) for pattern in skip_patterns)
    
    def generate_report(self, output_file: str = None):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report_lines = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append("# ä»£ç å†—ä½™åˆ†ææŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(f"**åˆ†ææ—¶é—´**: {self.analysis_result['timestamp']}")
        report_lines.append("")
        
        # æ€»ä½“æ¦‚å†µ
        report_lines.append("## ğŸ“Š æ€»ä½“æ¦‚å†µ")
        report_lines.append(f"- **é‡å¤å‡½æ•°ç»„**: {len(self.analysis_result['duplicate_functions'])}")
        report_lines.append(f"- **å…¼å®¹æ€§åŒ…è£…å‡½æ•°**: {len(self.analysis_result['wrapper_functions'])}")
        report_lines.append(f"- **å†—ä½™è„šæœ¬ç»„**: {len(self.analysis_result['redundant_scripts'])}")
        report_lines.append(f"- **é…ç½®æ–‡ä»¶**: {len(self.analysis_result['redundant_configs'])}")
        report_lines.append("")
        
        # é‡å¤å‡½æ•°è¯¦æƒ…
        if self.analysis_result['duplicate_functions']:
            report_lines.append("## ğŸ”„ é‡å¤å‡½æ•°")
            for dup in self.analysis_result['duplicate_functions']:
                report_lines.append(f"### {dup['signature']} ({dup['count']} ä¸ªä½ç½®)")
                for loc in dup['locations']:
                    report_lines.append(f"- `{loc['file']}:{loc['line']}` - {loc['name']}")
                report_lines.append("")
        
        # å…¼å®¹æ€§åŒ…è£…å‡½æ•°
        if self.analysis_result['wrapper_functions']:
            report_lines.append("## ğŸ”— å…¼å®¹æ€§åŒ…è£…å‡½æ•°")
            for wrapper in self.analysis_result['wrapper_functions']:
                report_lines.append(f"- `{wrapper['file']}:{wrapper['line']}` - {wrapper['match']}")
            report_lines.append("")
        
        # å†—ä½™è„šæœ¬
        if self.analysis_result['redundant_scripts']:
            report_lines.append("## ğŸ“œ å†—ä½™è„šæœ¬åˆ†æ")
            for group in self.analysis_result['redundant_scripts']:
                report_lines.append(f"### {group['group']} ç±»è„šæœ¬ ({group['count']} ä¸ª)")
                for script in group['scripts']:
                    report_lines.append(f"- {script}")
                report_lines.append(f"**å»ºè®®**: {group['recommendation']}")
                report_lines.append("")
        
        # é…ç½®æ–‡ä»¶åˆ†æ
        if self.analysis_result['redundant_configs']:
            report_lines.append("## âš™ï¸ é…ç½®æ–‡ä»¶åˆ†æ")
            for config in self.analysis_result['redundant_configs']:
                report_lines.append(f"### {config['file']}")
                report_lines.append(f"- æ–‡ä»¶å¤§å°: {config['size']} å­—ç¬¦")
                report_lines.append(f"- è¡Œæ•°: {config['lines']}")
                report_lines.append(f"- å¥–åŠ±é…ç½®: {config['reward_configs']}")
                report_lines.append(f"- API URLs: {config['api_urls']}")
                report_lines.append(f"- æ–‡ä»¶è·¯å¾„: {config['file_paths']}")
                report_lines.append("")
        
        # å»ºè®®
        if self.analysis_result['recommendations']:
            report_lines.append("## ğŸ’¡ ä¼˜åŒ–å»ºè®®")
            for rec in self.analysis_result['recommendations']:
                priority_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}
                emoji = priority_emoji.get(rec['priority'], 'âšª')
                report_lines.append(f"### {emoji} {rec['category']} ({rec['priority']})")
                report_lines.append(f"**é—®é¢˜**: {rec['description']}")
                report_lines.append(f"**å»ºè®®**: {rec['action']}")
                report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        # è¾“å‡ºæŠ¥å‘Š
        if output_file:
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print(report_content)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»£ç å†—ä½™åˆ†æå·¥å…·')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    analyzer = CodeRedundancyAnalyzer()
    analyzer.analyze_all()
    
    output_file = args.output or f"reports/redundancy_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    analyzer.generate_report(output_file)

if __name__ == "__main__":
    main()
