#!/usr/bin/env python3
"""
æ•°æ®åº“è§†å›¾è¿ç§»è„šæœ¬ - ä¿®å¤ performance_amount ç»Ÿè®¡é—®é¢˜

é—®é¢˜æè¿°ï¼š
- æ•°æ®åº“è§†å›¾ä¸­çš„å¤šä¸ªé‡‘é¢å­—æ®µç»Ÿè®¡äº†æ‰€æœ‰åˆåŒï¼ˆåŒ…æ‹¬å†å²åˆåŒï¼‰
- éœ€æ±‚æ˜¯ç´¯è®¡é‡‘é¢ç»Ÿè®¡åªè®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
- å†å²å·¥å•ä»…ä½œä¸ºåå°è®¡ç®—çš„é€»è¾‘æ•°æ®ï¼Œä¸å‚ä¸å‰ç«¯çš„æ•°æ®ç»Ÿè®¡

ä¿®å¤å†…å®¹ï¼š
1. é‡æ–°åˆ›å»º housekeeper_stats è§†å›¾ï¼Œæ‰€æœ‰ç´¯è®¡é‡‘é¢å­—æ®µåªç»Ÿè®¡éå†å²åˆåŒ
2. é‡æ–°åˆ›å»º project_stats è§†å›¾ï¼Œæ‰€æœ‰ç´¯è®¡é‡‘é¢å­—æ®µåªç»Ÿè®¡éå†å²åˆåŒ
3. é‡æ–°åˆ›å»º activity_stats è§†å›¾ï¼Œæ‰€æœ‰ç´¯è®¡é‡‘é¢å­—æ®µåªç»Ÿè®¡éå†å²åˆåŒ

ä½¿ç”¨æ–¹æ³•:
    python scripts/migrate_views_fix_performance_amount.py --db performance_data.db
    python scripts/migrate_views_fix_performance_amount.py --db performance_data.db --dry-run
"""

import sqlite3
import os
import sys
import argparse
import logging
from datetime import datetime

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(f'migrate_views_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        ]
    )

def check_database_exists(db_path: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(db_path):
        logging.error(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    return True

def backup_database(db_path: str) -> str:
    """å¤‡ä»½æ•°æ®åº“æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = f"{db_path}.backup_{timestamp}"
    
    try:
        import shutil
        shutil.copy2(db_path, backup_path)
        logging.info(f"æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
        return backup_path
    except Exception as e:
        logging.error(f"å¤‡ä»½æ•°æ®åº“å¤±è´¥: {e}")
        raise

def check_views_exist(conn: sqlite3.Connection) -> dict:
    """æ£€æŸ¥è§†å›¾æ˜¯å¦å­˜åœ¨"""
    cursor = conn.cursor()
    
    views_to_check = ['housekeeper_stats', 'project_stats', 'activity_stats']
    view_status = {}
    
    for view_name in views_to_check:
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='view' AND name=?
        """, (view_name,))
        
        exists = cursor.fetchone() is not None
        view_status[view_name] = exists
        
        if exists:
            logging.info(f"âœ… è§†å›¾ {view_name} å­˜åœ¨")
        else:
            logging.warning(f"âš ï¸ è§†å›¾ {view_name} ä¸å­˜åœ¨")
    
    return view_status

def drop_views(conn: sqlite3.Connection, dry_run: bool = False) -> bool:
    """åˆ é™¤ç°æœ‰è§†å›¾"""
    views_to_drop = ['housekeeper_stats', 'project_stats', 'activity_stats']
    
    try:
        cursor = conn.cursor()
        
        for view_name in views_to_drop:
            sql = f"DROP VIEW IF EXISTS {view_name}"
            
            if dry_run:
                logging.info(f"[DRY RUN] å°†æ‰§è¡Œ: {sql}")
            else:
                cursor.execute(sql)
                logging.info(f"âœ… åˆ é™¤è§†å›¾: {view_name}")
        
        if not dry_run:
            conn.commit()
            
        return True
        
    except Exception as e:
        logging.error(f"åˆ é™¤è§†å›¾å¤±è´¥: {e}")
        if not dry_run:
            conn.rollback()
        return False

def create_fixed_views(conn: sqlite3.Connection, dry_run: bool = False) -> bool:
    """åˆ›å»ºä¿®å¤åçš„è§†å›¾"""
    
    # ä¿®å¤åçš„ housekeeper_stats è§†å›¾
    housekeeper_stats_sql = """
    CREATE VIEW housekeeper_stats AS
    SELECT
        housekeeper,
        activity_code,
        COUNT(*) as contract_count,
        -- ğŸ”§ ä¿®å¤ï¼šç´¯è®¡åˆåŒé‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN contract_amount ELSE 0 END) as total_amount,
        -- ğŸ”§ ä¿®å¤ï¼šç´¯è®¡è®¡å…¥ä¸šç»©é‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN performance_amount ELSE 0 END) as performance_amount,
        -- åŒè½¨ç»Ÿè®¡ï¼ˆä¸Šæµ·ç‰¹æœ‰ï¼‰
        SUM(CASE WHEN order_type = 'platform' THEN 1 ELSE 0 END) as platform_count,
        -- ğŸ”§ ä¿®å¤ï¼šç´¯è®¡å¹³å°å•é‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN order_type = 'platform' AND is_historical = FALSE THEN contract_amount ELSE 0 END) as platform_amount,
        SUM(CASE WHEN order_type = 'self_referral' THEN 1 ELSE 0 END) as self_referral_count,
        -- ğŸ”§ ä¿®å¤ï¼šç´¯è®¡è‡ªå¼•å•é‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN order_type = 'self_referral' AND is_historical = FALSE THEN contract_amount ELSE 0 END) as self_referral_amount,
        -- å†å²åˆåŒç»Ÿè®¡ï¼ˆåŒ—äº¬9æœˆç‰¹æœ‰ï¼‰
        SUM(CASE WHEN is_historical = TRUE THEN 1 ELSE 0 END) as historical_count,
        SUM(CASE WHEN is_historical = FALSE THEN 1 ELSE 0 END) as new_count
    FROM performance_data
    GROUP BY housekeeper, activity_code
    """
    
    # ä¿®å¤åçš„ project_stats è§†å›¾
    project_stats_sql = """
    CREATE VIEW project_stats AS
    SELECT
        project_id,
        activity_code,
        COUNT(*) as contract_count,
        -- ğŸ”§ ä¿®å¤ï¼šå·¥å•ç´¯è®¡åˆåŒé‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN contract_amount ELSE 0 END) as total_amount,
        -- ğŸ”§ ä¿®å¤ï¼šå·¥å•ç´¯è®¡ä¸šç»©é‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN performance_amount ELSE 0 END) as performance_amount
    FROM performance_data
    WHERE project_id IS NOT NULL
    GROUP BY project_id, activity_code
    """
    
    # ä¿®å¤åçš„ activity_stats è§†å›¾
    activity_stats_sql = """
    CREATE VIEW activity_stats AS
    SELECT
        activity_code,
        COUNT(*) as total_contracts,
        COUNT(DISTINCT housekeeper) as unique_housekeepers,
        -- ğŸ”§ ä¿®å¤ï¼šæ´»åŠ¨æ€»åˆåŒé‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN contract_amount ELSE 0 END) as total_amount,
        -- ğŸ”§ ä¿®å¤ï¼šæ´»åŠ¨æ€»ä¸šç»©é‡‘é¢ä»…è®¡å…¥æ–°å·¥å•ï¼Œä¸è®¡å…¥å†å²å·¥å•
        SUM(CASE WHEN is_historical = FALSE THEN performance_amount ELSE 0 END) as total_performance_amount,
        -- ğŸ”§ ä¿®å¤ï¼šå¹³å‡åˆåŒé‡‘é¢ä»…åŸºäºæ–°å·¥å•è®¡ç®—ï¼Œä¸åŒ…å«å†å²å·¥å•
        AVG(CASE WHEN is_historical = FALSE THEN contract_amount ELSE NULL END) as avg_contract_amount,
        MIN(created_at) as first_contract_time,
        MAX(created_at) as last_contract_time
    FROM performance_data
    GROUP BY activity_code
    """
    
    views_to_create = [
        ('housekeeper_stats', housekeeper_stats_sql),
        ('project_stats', project_stats_sql),
        ('activity_stats', activity_stats_sql)
    ]
    
    try:
        cursor = conn.cursor()
        
        for view_name, sql in views_to_create:
            if dry_run:
                logging.info(f"[DRY RUN] å°†åˆ›å»ºè§†å›¾: {view_name}")
                logging.debug(f"[DRY RUN] SQL: {sql}")
            else:
                cursor.execute(sql)
                logging.info(f"âœ… åˆ›å»ºè§†å›¾: {view_name}")
        
        if not dry_run:
            conn.commit()
            
        return True
        
    except Exception as e:
        logging.error(f"åˆ›å»ºè§†å›¾å¤±è´¥: {e}")
        if not dry_run:
            conn.rollback()
        return False

def update_schema_version(conn: sqlite3.Connection, dry_run: bool = False) -> bool:
    """æ›´æ–°schemaç‰ˆæœ¬ä¿¡æ¯"""
    version = "1.0.2"
    description = "Fix all amount calculations to exclude historical contracts"
    
    try:
        cursor = conn.cursor()
        
        sql = """
        INSERT OR REPLACE INTO schema_version (version, description, applied_at)
        VALUES (?, ?, CURRENT_TIMESTAMP)
        """
        
        if dry_run:
            logging.info(f"[DRY RUN] å°†æ›´æ–°schemaç‰ˆæœ¬åˆ°: {version}")
        else:
            cursor.execute(sql, (version, description))
            conn.commit()
            logging.info(f"âœ… æ›´æ–°schemaç‰ˆæœ¬åˆ°: {version}")
            
        return True
        
    except Exception as e:
        logging.error(f"æ›´æ–°schemaç‰ˆæœ¬å¤±è´¥: {e}")
        if not dry_run:
            conn.rollback()
        return False

def verify_migration(conn: sqlite3.Connection) -> bool:
    """éªŒè¯è¿ç§»ç»“æœ"""
    try:
        cursor = conn.cursor()
        
        # æ£€æŸ¥è§†å›¾æ˜¯å¦å­˜åœ¨
        view_status = check_views_exist(conn)
        all_views_exist = all(view_status.values())
        
        if not all_views_exist:
            logging.error("âŒ éƒ¨åˆ†è§†å›¾åˆ›å»ºå¤±è´¥")
            return False
        
        # æµ‹è¯•è§†å›¾æŸ¥è¯¢
        test_queries = [
            "SELECT COUNT(*) FROM housekeeper_stats",
            "SELECT COUNT(*) FROM project_stats", 
            "SELECT COUNT(*) FROM activity_stats"
        ]
        
        for query in test_queries:
            try:
                cursor.execute(query)
                result = cursor.fetchone()[0]
                logging.info(f"âœ… è§†å›¾æŸ¥è¯¢æµ‹è¯•é€šè¿‡: {query} -> {result} è¡Œ")
            except Exception as e:
                logging.error(f"âŒ è§†å›¾æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {query} -> {e}")
                return False
        
        # æ£€æŸ¥schemaç‰ˆæœ¬
        cursor.execute("SELECT version, description FROM schema_version ORDER BY applied_at DESC LIMIT 1")
        version_info = cursor.fetchone()
        if version_info:
            logging.info(f"âœ… å½“å‰schemaç‰ˆæœ¬: {version_info[0]} - {version_info[1]}")
        
        return True
        
    except Exception as e:
        logging.error(f"éªŒè¯è¿ç§»å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®åº“è§†å›¾è¿ç§»è„šæœ¬ - ä¿®å¤ performance_amount ç»Ÿè®¡é—®é¢˜')
    parser.add_argument('--db', default='performance_data.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dry-run', action='store_true', help='åªæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…æ‰§è¡Œ')
    parser.add_argument('--no-backup', action='store_true', help='è·³è¿‡æ•°æ®åº“å¤‡ä»½ï¼ˆä¸æ¨èï¼‰')
    
    args = parser.parse_args()
    
    setup_logging()
    
    logging.info("ğŸ”§ æ•°æ®åº“è§†å›¾è¿ç§»è„šæœ¬ - ä¿®å¤ performance_amount ç»Ÿè®¡é—®é¢˜")
    logging.info("=" * 60)
    
    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    if not check_database_exists(args.db):
        return 1
    
    # å¤‡ä»½æ•°æ®åº“
    if not args.dry_run and not args.no_backup:
        try:
            backup_path = backup_database(args.db)
            logging.info(f"ğŸ’¾ æ•°æ®åº“å·²å¤‡ä»½ï¼Œå¦‚æœ‰é—®é¢˜å¯æ¢å¤: cp {backup_path} {args.db}")
        except Exception as e:
            logging.error(f"å¤‡ä»½å¤±è´¥ï¼Œåœæ­¢è¿ç§»: {e}")
            return 1
    
    # è¿æ¥æ•°æ®åº“
    try:
        conn = sqlite3.connect(args.db)
        logging.info(f"ğŸ“Š è¿æ¥æ•°æ®åº“: {args.db}")
        
        # æ£€æŸ¥å½“å‰è§†å›¾çŠ¶æ€
        logging.info("\nğŸ“‹ æ£€æŸ¥å½“å‰è§†å›¾çŠ¶æ€:")
        view_status = check_views_exist(conn)
        
        # æ‰§è¡Œè¿ç§»
        logging.info(f"\nğŸš€ å¼€å§‹è¿ç§» {'(é¢„è§ˆæ¨¡å¼)' if args.dry_run else ''}:")
        
        # 1. åˆ é™¤ç°æœ‰è§†å›¾
        if not drop_views(conn, args.dry_run):
            logging.error("âŒ åˆ é™¤è§†å›¾å¤±è´¥ï¼Œåœæ­¢è¿ç§»")
            return 1
        
        # 2. åˆ›å»ºä¿®å¤åçš„è§†å›¾
        if not create_fixed_views(conn, args.dry_run):
            logging.error("âŒ åˆ›å»ºè§†å›¾å¤±è´¥ï¼Œåœæ­¢è¿ç§»")
            return 1
        
        # 3. æ›´æ–°schemaç‰ˆæœ¬
        if not update_schema_version(conn, args.dry_run):
            logging.error("âŒ æ›´æ–°schemaç‰ˆæœ¬å¤±è´¥")
            return 1
        
        # 4. éªŒè¯è¿ç§»ç»“æœ
        if not args.dry_run:
            logging.info("\nğŸ” éªŒè¯è¿ç§»ç»“æœ:")
            if not verify_migration(conn):
                logging.error("âŒ è¿ç§»éªŒè¯å¤±è´¥")
                return 1
        
        if args.dry_run:
            logging.info("\nâœ… é¢„è§ˆå®Œæˆï¼è¦å®é™…æ‰§è¡Œè¿ç§»ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°")
        else:
            logging.info("\nâœ… è¿ç§»å®Œæˆï¼performance_amount ç°åœ¨åªç»Ÿè®¡æ–°å·¥å•ï¼Œä¸åŒ…æ‹¬å†å²å·¥å•")
            logging.info("ğŸ’¡ å»ºè®®è¿è¡Œæµ‹è¯•éªŒè¯ä¿®å¤æ•ˆæœ")
        
        return 0
        
    except Exception as e:
        logging.error(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1
        
    finally:
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
