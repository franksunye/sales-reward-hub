#!/usr/bin/env python3
"""
æ¸…ç©ºæ—§ç³»ç»Ÿæ•°æ®è„šæœ¬
ç‰ˆæœ¬: v1.0
åˆ›å»ºæ—¥æœŸ: 2025-09-15

ç”¨é€”ï¼šæ¸…ç©ºæ—§ç³»ç»Ÿçš„æ‰€æœ‰æ•°æ®æ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- CSVæ•°æ®æ–‡ä»¶ï¼ˆåˆåŒæ•°æ®ã€ä¸šç»©æ•°æ®ï¼‰
- JSONçŠ¶æ€æ–‡ä»¶ï¼ˆå‘é€çŠ¶æ€ã€ä»»åŠ¡çŠ¶æ€ï¼‰
- SQLiteæ•°æ®åº“æ–‡ä»¶
- å½’æ¡£æ–‡ä»¶
- ä¸´æ—¶æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/clear_old_system_data.py [--confirm] [--keep-archive]
"""

import os
import sys
import argparse
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_data_files():
    """è·å–æ‰€æœ‰éœ€è¦æ¸…ç†çš„æ•°æ®æ–‡ä»¶åˆ—è¡¨"""
    
    # åŸºäºconfig.pyä¸­çš„é…ç½®å®šä¹‰æ•°æ®æ–‡ä»¶
    data_files = {
        # åŒ—äº¬åœ°åŒºæ•°æ®æ–‡ä»¶
        'beijing': [
            'state/ContractData-BJ-Aug.csv',
            'state/PerformanceData-BJ-Aug.csv', 
            'state/send_status_bj_aug.json',
            'state/ContractData-BJ-Sep.csv',
            'state/PerformanceData-BJ-Sep.csv',
            'state/send_status_bj_sep.json',
        ],
        
        # ä¸Šæµ·åœ°åŒºæ•°æ®æ–‡ä»¶
        'shanghai': [
            'state/ContractData-SH-Aug.csv',
            'state/PerformanceData-SH-Aug.csv',
            'state/send_status_sh_aug.json',
            'state/ContractData-SH-Sep.csv', 
            'state/PerformanceData-SH-Sep.csv',
            'state/send_status_shanghai_sep.json',
        ],
        
        # ç³»ç»ŸçŠ¶æ€æ–‡ä»¶
        'system': [
            'state/pending_orders_reminder_status.json',
            'state/daily_service_report_record.csv',
            'state/daily_service_report_record.json',
            'state/sla_violations.json',
            'metabase_session.json',
        ],
        
        # æ•°æ®åº“æ–‡ä»¶
        'database': [
            'performance_data.db',
            'tasks.db',
        ],
        
        # æµ‹è¯•æ–‡ä»¶
        'test': [
            'modules/core/performance_data_BJ-JUN_20250908_083348.csv',
            'modules/core/tests/performance_data_SH-APR_20250908_085943.csv',
            'modules/core/tests/performance_data_SH-AUG_20250908_085943.csv',
            'modules/core/tests/performance_data_SH-SEP_dual_track_20250908_085943.csv',
        ]
    }
    
    return data_files

def clear_files(file_list, category_name, dry_run=False):
    """æ¸…ç†æŒ‡å®šçš„æ–‡ä»¶åˆ—è¡¨"""
    cleared_count = 0
    
    logging.info(f"ğŸ—‚ï¸  æ¸…ç† {category_name} æ–‡ä»¶...")
    
    for file_path in file_list:
        if os.path.exists(file_path):
            if dry_run:
                logging.info(f"  [DRY RUN] å°†åˆ é™¤: {file_path}")
            else:
                try:
                    os.remove(file_path)
                    logging.info(f"  âœ… å·²åˆ é™¤: {file_path}")
                    cleared_count += 1
                except Exception as e:
                    logging.error(f"  âŒ åˆ é™¤å¤±è´¥: {file_path} - {e}")
        else:
            logging.debug(f"  â­ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if not dry_run:
        logging.info(f"  ğŸ“Š {category_name}: æ¸…ç†äº† {cleared_count} ä¸ªæ–‡ä»¶")
    
    return cleared_count

def clear_archive_directory(keep_archive=False, dry_run=False):
    """æ¸…ç†å½’æ¡£ç›®å½•"""
    archive_dir = 'archive'
    
    if not os.path.exists(archive_dir):
        logging.info("ğŸ“ å½’æ¡£ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return 0
    
    if keep_archive:
        logging.info("ğŸ“ ä¿ç•™å½’æ¡£ç›®å½•ï¼ˆ--keep-archive é€‰é¡¹ï¼‰")
        return 0
    
    cleared_count = 0
    
    logging.info("ğŸ—‚ï¸  æ¸…ç†å½’æ¡£ç›®å½•...")
    
    for root, dirs, files in os.walk(archive_dir, topdown=False):
        for file in files:
            file_path = os.path.join(root, file)
            if dry_run:
                logging.info(f"  [DRY RUN] å°†åˆ é™¤: {file_path}")
            else:
                try:
                    os.remove(file_path)
                    logging.debug(f"  âœ… å·²åˆ é™¤: {file_path}")
                    cleared_count += 1
                except Exception as e:
                    logging.error(f"  âŒ åˆ é™¤å¤±è´¥: {file_path} - {e}")
        
        # åˆ é™¤ç©ºç›®å½•
        for dir in dirs:
            dir_path = os.path.join(root, dir)
            if dry_run:
                logging.info(f"  [DRY RUN] å°†åˆ é™¤ç›®å½•: {dir_path}")
            else:
                try:
                    os.rmdir(dir_path)
                    logging.debug(f"  âœ… å·²åˆ é™¤ç›®å½•: {dir_path}")
                except Exception as e:
                    logging.debug(f"  â­ï¸  ç›®å½•éç©ºæˆ–åˆ é™¤å¤±è´¥: {dir_path}")
    
    # åˆ é™¤å½’æ¡£æ ¹ç›®å½•
    if not dry_run:
        try:
            os.rmdir(archive_dir)
            logging.info(f"  âœ… å·²åˆ é™¤å½’æ¡£æ ¹ç›®å½•: {archive_dir}")
        except Exception as e:
            logging.debug(f"  â­ï¸  å½’æ¡£æ ¹ç›®å½•åˆ é™¤å¤±è´¥: {e}")
    
    if not dry_run:
        logging.info(f"  ğŸ“Š å½’æ¡£ç›®å½•: æ¸…ç†äº† {cleared_count} ä¸ªæ–‡ä»¶")
    
    return cleared_count

def main():
    parser = argparse.ArgumentParser(description='æ¸…ç©ºæ—§ç³»ç»Ÿæ•°æ®')
    parser.add_argument('--confirm', action='store_true', 
                       help='ç¡®è®¤æ‰§è¡Œæ¸…ç†ï¼ˆä¸åŠ æ­¤å‚æ•°å°†åªæ˜¾ç¤ºè¦åˆ é™¤çš„æ–‡ä»¶ï¼‰')
    parser.add_argument('--keep-archive', action='store_true',
                       help='ä¿ç•™å½’æ¡£ç›®å½•')
    parser.add_argument('--category', choices=['beijing', 'shanghai', 'system', 'database', 'test', 'all'],
                       default='all', help='æŒ‡å®šæ¸…ç†çš„æ•°æ®ç±»åˆ«')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
    if not os.path.exists('modules/config.py'):
        logging.error("âŒ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    
    dry_run = not args.confirm
    
    if dry_run:
        logging.info("ğŸ” é¢„è§ˆæ¨¡å¼ - æ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ–‡ä»¶ï¼ˆä½¿ç”¨ --confirm å‚æ•°å®é™…æ‰§è¡Œåˆ ç†ï¼‰")
    else:
        logging.info("ğŸ—‘ï¸  å¼€å§‹æ¸…ç†æ—§ç³»ç»Ÿæ•°æ®...")
    
    data_files = get_data_files()
    total_cleared = 0
    
    # æ ¹æ®é€‰æ‹©çš„ç±»åˆ«æ¸…ç†æ–‡ä»¶
    if args.category == 'all':
        categories = data_files.keys()
    else:
        categories = [args.category]
    
    for category in categories:
        if category in data_files:
            cleared = clear_files(data_files[category], category, dry_run)
            total_cleared += cleared
    
    # æ¸…ç†å½’æ¡£ç›®å½•
    if args.category in ['all', 'system']:
        archive_cleared = clear_archive_directory(args.keep_archive, dry_run)
        total_cleared += archive_cleared
    
    if dry_run:
        logging.info("ğŸ” é¢„è§ˆå®Œæˆ - ä½¿ç”¨ --confirm å‚æ•°å®é™…æ‰§è¡Œæ¸…ç†")
    else:
        logging.info(f"ğŸ‰ æ¸…ç†å®Œæˆï¼æ€»å…±æ¸…ç†äº† {total_cleared} ä¸ªæ–‡ä»¶")

if __name__ == '__main__':
    main()
