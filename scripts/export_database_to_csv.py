#!/usr/bin/env python3
"""
æ•°æ®åº“å¯¼å‡ºå·¥å…·

ä»SQLiteæ•°æ®åº“å¯¼å‡ºæŒ‡å®šæ´»åŠ¨çš„æ•°æ®åˆ°CSVæ–‡ä»¶ã€‚
ç”¨äºæ›¿ä»£è‡ªåŠ¨ç”ŸæˆCSVæ–‡ä»¶çš„åŠŸèƒ½ï¼Œæä¾›æŒ‰éœ€å¯¼å‡ºã€‚
"""

import sys
import os
import sqlite3
import csv
import json
from datetime import datetime
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

def export_activity_to_csv(db_path: str, activity_code: str, output_path: str = None):
    """ä»æ•°æ®åº“å¯¼å‡ºæŒ‡å®šæ´»åŠ¨çš„æ•°æ®åˆ°CSVæ–‡ä»¶"""
    
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return None
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if not output_path:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = f"performance_data_{activity_code}_{timestamp}.csv"
    
    try:
        with sqlite3.connect(db_path) as conn:
            # æŸ¥è¯¢æŒ‡å®šæ´»åŠ¨çš„æ•°æ®
            cursor = conn.execute("""
                SELECT * FROM performance_data 
                WHERE activity_code = ? 
                ORDER BY created_at
            """, (activity_code,))
            
            rows = cursor.fetchall()
            
            if not rows:
                print(f"âš ï¸ æ´»åŠ¨ {activity_code} æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
                return None
            
            # è·å–åˆ—å
            column_names = [description[0] for description in cursor.description]
            
            # å†™å…¥CSVæ–‡ä»¶
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                
                # å†™å…¥è¡¨å¤´
                writer.writerow(column_names)
                
                # å†™å…¥æ•°æ®è¡Œ
                for row in rows:
                    # å¤„ç†extensionså­—æ®µï¼ˆJSONæ ¼å¼ï¼‰
                    processed_row = []
                    for i, value in enumerate(row):
                        if column_names[i] == 'extensions' and value:
                            try:
                                # è§£æJSONå¹¶å±•å¼€å­—æ®µ
                                extensions = json.loads(value)
                                processed_row.append(json.dumps(extensions, ensure_ascii=False))
                            except:
                                processed_row.append(value)
                        else:
                            processed_row.append(value)
                    
                    writer.writerow(processed_row)
            
            print(f"âœ… å¯¼å‡ºå®Œæˆ: {output_path}")
            print(f"   æ´»åŠ¨ä»£ç : {activity_code}")
            print(f"   è®°å½•æ•°é‡: {len(rows)}")
            print(f"   å­—æ®µæ•°é‡: {len(column_names)}")
            
            return output_path
            
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return None

def export_activity_to_compatible_csv(db_path: str, activity_code: str, output_path: str = None):
    """å¯¼å‡ºå…¼å®¹æ—§æ ¼å¼çš„CSVæ–‡ä»¶"""
    
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return None
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if not output_path:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = f"performance_data_{activity_code}_{timestamp}.csv"
    
    try:
        with sqlite3.connect(db_path) as conn:
            # æŸ¥è¯¢æ•°æ®å¹¶é‡æ„ä¸ºå…¼å®¹æ ¼å¼
            cursor = conn.execute("""
                SELECT 
                    activity_code as 'æ´»åŠ¨ç¼–å·',
                    contract_id as 'åˆåŒID(_id)',
                    housekeeper as 'ç®¡å®¶(serviceHousekeeper)',
                    service_provider as 'æœåŠ¡å•†(orgName)',
                    contract_amount as 'åˆåŒé‡‘é¢(adjustRefundMoney)',
                    performance_amount as 'è®¡å…¥ä¸šç»©é‡‘é¢',
                    reward_types as 'å¥–åŠ±ç±»å‹',
                    reward_names as 'å¥–åŠ±åç§°',
                    is_historical as 'æ˜¯å¦å†å²åˆåŒ',
                    extensions,
                    created_at as 'åˆ›å»ºæ—¶é—´'
                FROM performance_data 
                WHERE activity_code = ? 
                ORDER BY created_at
            """, (activity_code,))
            
            rows = cursor.fetchall()
            
            if not rows:
                print(f"âš ï¸ æ´»åŠ¨ {activity_code} æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
                return None
            
            # è·å–åˆ—å
            column_names = [description[0] for description in cursor.description]
            
            # å†™å…¥CSVæ–‡ä»¶
            with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=[])
                
                # å¤„ç†ç¬¬ä¸€è¡Œæ•°æ®ä»¥ç¡®å®šæ‰€æœ‰å­—æ®µ
                all_fieldnames = set()
                processed_rows = []
                
                for row in rows:
                    row_dict = dict(zip(column_names, row))
                    
                    # å¤„ç†extensionså­—æ®µ
                    if row_dict.get('extensions'):
                        try:
                            extensions = json.loads(row_dict['extensions'])
                            row_dict.update(extensions)
                        except:
                            pass
                    
                    # ç§»é™¤extensionså­—æ®µ
                    row_dict.pop('extensions', None)
                    
                    # å¤„ç†å¸ƒå°”å€¼
                    if 'æ˜¯å¦å†å²åˆåŒ' in row_dict:
                        row_dict['æ˜¯å¦å†å²åˆåŒ'] = 'Y' if row_dict['æ˜¯å¦å†å²åˆåŒ'] else 'N'
                    
                    all_fieldnames.update(row_dict.keys())
                    processed_rows.append(row_dict)
                
                # é‡æ–°åˆ›å»ºwriter withæ‰€æœ‰å­—æ®µ
                writer = csv.DictWriter(csvfile, fieldnames=sorted(all_fieldnames))
                writer.writeheader()
                writer.writerows(processed_rows)
            
            print(f"âœ… å…¼å®¹æ ¼å¼å¯¼å‡ºå®Œæˆ: {output_path}")
            print(f"   æ´»åŠ¨ä»£ç : {activity_code}")
            print(f"   è®°å½•æ•°é‡: {len(rows)}")
            print(f"   å­—æ®µæ•°é‡: {len(all_fieldnames)}")
            
            return output_path
            
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return None

def list_activities(db_path: str):
    """åˆ—å‡ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰æ´»åŠ¨"""
    
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.execute("""
                SELECT activity_code, COUNT(*) as record_count, 
                       MIN(created_at) as first_record, 
                       MAX(created_at) as last_record
                FROM performance_data 
                GROUP BY activity_code 
                ORDER BY activity_code
            """)
            
            activities = cursor.fetchall()
            
            if not activities:
                print("ğŸ“Š æ•°æ®åº“ä¸­æ²¡æœ‰æ´»åŠ¨æ•°æ®")
                return
            
            print("ğŸ“Š æ•°æ®åº“ä¸­çš„æ´»åŠ¨åˆ—è¡¨:")
            print("-" * 60)
            print(f"{'æ´»åŠ¨ä»£ç ':<15} {'è®°å½•æ•°':<8} {'é¦–æ¬¡è®°å½•':<20} {'æœ€æ–°è®°å½•':<20}")
            print("-" * 60)
            
            for activity_code, count, first, last in activities:
                print(f"{activity_code:<15} {count:<8} {first:<20} {last:<20}")
            
            print("-" * 60)
            print(f"æ€»è®¡: {len(activities)} ä¸ªæ´»åŠ¨")
            
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®åº“å¯¼å‡ºå·¥å…·')
    parser.add_argument('--db', default='performance_data.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--activity', help='æ´»åŠ¨ä»£ç  (å¦‚: BJ-SEP)')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰æ´»åŠ¨')
    parser.add_argument('--compatible', action='store_true', help='å¯¼å‡ºå…¼å®¹æ—§æ ¼å¼çš„CSV')
    
    args = parser.parse_args()
    
    print("ğŸ” æ•°æ®åº“å¯¼å‡ºå·¥å…·")
    print("=" * 50)
    
    if args.list:
        list_activities(args.db)
        return
    
    if not args.activity:
        print("âŒ è¯·æŒ‡å®šæ´»åŠ¨ä»£ç  (ä½¿ç”¨ --activity)")
        print("ğŸ’¡ ä½¿ç”¨ --list æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ´»åŠ¨")
        return
    
    if args.compatible:
        result = export_activity_to_compatible_csv(args.db, args.activity, args.output)
    else:
        result = export_activity_to_csv(args.db, args.activity, args.output)
    
    if result:
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"   æŸ¥çœ‹æ–‡ä»¶: head -5 {result}")
        print(f"   è®°å½•æ•°é‡: wc -l {result}")
        print(f"   å¯¹æ¯”éªŒè¯: å¯ä¸æ—§æ¶æ„è¾“å‡ºè¿›è¡Œå¯¹æ¯”")

if __name__ == "__main__":
    main()
